# Harmonyを使ったLLMアプリ開発の一般論

この文書は、このリポジトリの実装（特に `internal/llm/openai.go` と `internal/app/app.go`）をもとに、Harmony形式プロンプトを使うLLMアプリを設計・実装するときの一般論を整理したものです。

## 1. まず責務を分離する

LLMアプリは、次の責務を分けると保守しやすくなります。

- アプリ層: 入出力、フォーマット判定、進捗表示、設定ロード
- LLMクライアント層: エンドポイント選択、HTTP通信、プロンプト生成
- ドメイン層: チャンク分割、Markdown/PDFなど形式別の変換

この分離により、プロンプト仕様変更（Harmony化など）が起きても、影響範囲を `llm` 層に閉じ込められます。

## 2. Harmonyは「completion用の会話構造」として扱う

Harmonyは completion API でも会話状態を明示できる形式です。実装上の最小パターンは次です。

1. `system` メッセージを明示する
2. `user` メッセージを明示する
3. 末尾を `assistant` の `final` チャネル開始で終える

例（概念）:

```text
<|start|>system<|message|>{system instruction}<|end|>
<|start|>user<|message|>{user input}<|end|>
<|start|>assistant<|channel|>final<|message|>
```

この形を固定しておくと、モデルやランタイムが変わっても挙動を比較しやすくなります。

## 3. systemプロンプトは「出力制約」を短く強く書く

翻訳・抽出・整形などのタスクでは、systemプロンプトに以下を含めるのが有効です。

- 何をするか（例: 何語から何語に翻訳するか）
- 何を守るか（例: Markdown構造を維持）
- 何を禁止するか（例: 解説や余計な文を出力しない）

このリポジトリでも「翻訳結果のみ出力」を明示しており、余計な付加文を減らしています。

## 4. chat/completionを抽象化し、Harmonyはcompletion側に閉じ込める

現実の運用では、モデルごとに `chat` しかない場合と `completion` しかない場合が混在します。対策として:

- クライアント公開APIは `Translate(...)` のように統一する
- 内部で `translateChat` と `translateCompletion` を分ける
- `auto` 判定で `/v1/models` の capability を見て分岐する

これで呼び出し側はモデル差異を意識せずに使えます。

## 5. Stopトークンを必ず設計する

completion + Harmonyでは、どこまで生成させるかを明示しないと、不要な追加生成が起きやすくなります。`stop` はモデル実装に合わせて複数候補を指定し、出力終端を安定化させるのが基本です。

## 6. 長文は先に分割し、形式ごとに翻訳単位を変える

一般にLLMアプリは入力をそのまま投げるより、次の方針のほうが安定します。

- プレーンテキスト: 文字数上限でチャンク分割
- Markdown: ASTベースで翻訳対象ノードだけ抽出
- PDF: 行やブロック単位で抽出して翻訳

「形式依存の前処理」をLLM呼び出し前に置くのが、品質とコストの両面で重要です。

## 7. 観測性を最初から入れる

LLMアプリは不具合の再現が難しいため、最低限の観測性を入れておくべきです。

- verboseログ（生成結果や進捗）
- promptログ（送信したsystem/userまたはHarmony全文）
- レスポンス異常時のHTTP status/bodyをエラーに含める

特にプロンプトログは、品質劣化の切り分け速度を大きく改善します。

## 8. セキュリティと設定管理を分ける

- APIキーなど秘密情報は設定ファイルと分離
- 保存する場合は暗号化し、復号の導線を統一
- CLIフラグ、環境変数、設定ファイルの優先順位を明確化

LLM機能そのものより、運用時にはこの周辺設計が障害率を左右します。

## 9. テストは「経路選択」と「プロンプト形状」を守る

Harmony導入時に最低限守るべきテスト観点:

- `auto` のとき completion/chat が正しく選ばれるか
- Harmonyプロンプトに期待トークン列が含まれるか
- APIレスポンスのゼロ件・異常系を適切にエラー化できるか

この3点を押さえると、モデル変更やリファクタ時の回帰を早く検出できます。

## 10. まとめ

Harmonyを使ったLLMアプリの要点は、次の3つに集約できます。

1. プロンプト構造（role/channel/stop）を固定し、completion挙動を安定化する
2. モデル差異（chat/completion）をアプリ層から隠蔽する
3. 入力前処理・観測性・テストを先に設計して運用崩壊を防ぐ

この順序で設計すると、翻訳以外の要約・抽出・変換アプリにもそのまま展開できます。
